{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6cb2ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 10:57:56.252731: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-12.2/lib64\n",
      "2024-07-13 10:57:56.252757: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "# only if you are using CUDA devices\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from conf import BASE_DIR\n",
    "from Applications.Poisoning.gen_configs import main as gen_configs\n",
    "from util import LoggedGradientTape, ModelTmpState, CSVLogger, measure_time, GradientLoggingContext\n",
    "from Applications.Poisoning.unlearn.core import approx_retraining\n",
    "\n",
    "\n",
    "model_folder = BASE_DIR/'models'/'poisoning'\n",
    "train_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'train.json'\n",
    "poison_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'poison.json'\n",
    "unlearn_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'unlearn.json'\n",
    "\n",
    "gen_configs(model_folder, train_conf, poison_conf, unlearn_conf)\n",
    "\n",
    "from Applications.Poisoning.poison.poison_models import train_poisoned\n",
    "from Applications.Poisoning.configs.demo.config import Config\n",
    "\n",
    "poisoned_folder = model_folder/'budget-10000'/'seed-42'\n",
    "clean_folder = model_folder/'clean'\n",
    "first_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'first-order'\n",
    "second_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'second-order'\n",
    "\n",
    "\n",
    "poison_kwargs = Config.from_json(poisoned_folder/'poison_config.json')\n",
    "train_kwargs = Config.from_json(poisoned_folder/'train_config.json')\n",
    "\n",
    "poisoned_weights = poisoned_folder/'best_model.hdf5'       # model that has been trained on poisoned data\n",
    "fo_repaired_weights = poisoned_folder/'fo_repaired.hdf5'   # model weights after unlearning (first-order)\n",
    "so_repaired_weights = poisoned_folder/'so_repaired.hdf5'   # model weights after unlearning (second-order)\n",
    "injector_path = poisoned_folder/'injector.pkl'             # cached injector for reproducibility\n",
    "clean_results = model_folder/'clean'/'train_results.json'  # path to reference results on clean dataset\n",
    "\n",
    "from Applications.Poisoning.unlearn.first_order import run_experiment as fo_experiment\n",
    "from Applications.Poisoning.unlearn.second_order import run_experiment as so_experiment\n",
    "from Applications.Poisoning.unlearn.common import get_delta_idx, batch_pred, plot_cm, evaluate_model_diff, unlearn_update\n",
    "from Applications.Poisoning.unlearn.core import get_gradients_diff, get_inv_hvp_lissa\n",
    "\n",
    "\n",
    "fo_unlearn_kwargs = Config.from_json(poisoned_folder/'first-order'/'unlearn_config.json')\n",
    "so_unlearn_kwargs = Config.from_json(poisoned_folder/'second-order'/'unlearn_config.json')\n",
    "\n",
    "from Applications.Poisoning.train import main as train\n",
    "from Applications.Poisoning.evaluate import evaluate\n",
    "\n",
    "# train one clean and one poisoned model\n",
    "# datasets = ['Cifar10', 'Cifar100', 'SVHN', 'FashionMnist']\n",
    "datasets = ['Cifar100', 'Cifar10', 'SVHN']\n",
    "# modelnames = ['extractfeatures_VGG16', 'classifier_VGG16']\n",
    "modelnames = ['VGG16']\n",
    "# modelnames = ['VGG16', 'RESNET50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fb90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Applications.Poisoning.model import get_VGG16_CIFAR100, get_VGG16_CIFAR10, get_VGG16_SVHN\n",
    "from Applications.Poisoning.dataset import Cifar10, SVHN, FashionMnist, Cifar100\n",
    "from Applications.Poisoning.evaluate import evaluate\n",
    "from Applications.Poisoning.poison.injector import LabelflipInjector\n",
    "from os.path import dirname as parent\n",
    "from util import UnlearningResult, reduce_dataset\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def model_init():\n",
    "    return get_VGG16_CIFAR10\n",
    "def evaluate(model, data, weights_path):\n",
    "    (x_train, y_train), (x_test, y_test), (x_val, y_val) = data\n",
    "    model.load_weights(weights_path)\n",
    "    y_pred = model.predict(x=x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return acc\n",
    "\n",
    "def get_flatten_index(model):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Flatten):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def update_weights_after_flatten(model, d_theta, tau, flatten_weights_start_index):\n",
    "    updated_weights = []\n",
    "    d_theta_index = 0\n",
    "    for i, w in enumerate(model.trainable_weights):\n",
    "        if i >= flatten_weights_start_index and d_theta_index < len(d_theta):\n",
    "            updated_weights.append(w - tau * d_theta[d_theta_index])\n",
    "            d_theta_index += 1\n",
    "        else:\n",
    "            updated_weights.append(w)\n",
    "    return updated_weights\n",
    "\n",
    "def update_weights_before_flatten(model, d_theta, tau, flatten_weights_start_index):\n",
    "    updated_weights = []\n",
    "    d_theta_index = 0\n",
    "\n",
    "    for i, w in enumerate(model.trainable_weights):\n",
    "        if i < flatten_weights_start_index and d_theta_index < len(d_theta):\n",
    "            updated_weights.append(w - tau * d_theta[d_theta_index])\n",
    "            d_theta_index += 1\n",
    "        else:\n",
    "            updated_weights.append(w)\n",
    "    \n",
    "\n",
    "current_data = Cifar10.load()\n",
    "model = model_init()\n",
    "dataset = 'Cifar10'\n",
    "modelname = 'VGG16'\n",
    "model_folder = poisoned_folder/'first-order'\n",
    "update_targets = ['classifier', 'feature_extractor', 'both']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737e6829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 10:59:20.913036: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-07-13 10:59:20.913093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: conite-HP\n",
      "2024-07-13 10:59:20.913105: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: conite-HP\n",
      "2024-07-13 10:59:20.913313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.2\n",
      "2024-07-13 10:59:20.913352: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.2\n",
      "2024-07-13 10:59:20.913362: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.2\n",
      "2024-07-13 10:59:20.913833: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-13 10:59:21.011976: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-07-13 10:59:21.023816: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-07-13 10:59:21.032275: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-07-13 10:59:21.061669: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-07-13 10:59:21.072652: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8448"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = model_folder/'_Cifar10_VGG16_repaired_model.hdf5'\n",
    "evaluate(model=model(), data=current_data, weights_path=weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f043eb",
   "metadata": {},
   "source": [
    "## Unlearning\n",
    "\n",
    "Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ef34d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> reduction=1, new train size: 50000\n"
     ]
    }
   ],
   "source": [
    "# fo_experiment(poisoned_folder/'first-order', train_kwargs, poison_kwargs, fo_unlearn_kwargs, dataset=dataset, modelname=modelname, update_target=update_target)\n",
    "# inject label flips\n",
    "(x_train, y_train), (x_test, y_test), (x_val, y_val) = current_data\n",
    "verbose = 1\n",
    "reduction = 1\n",
    "order = 1\n",
    "unlearn_kwargs = fo_unlearn_kwargs\n",
    "y_train_orig = y_train.copy()\n",
    "injector_path = os.path.join(model_folder, 'injector.pkl')\n",
    "if os.path.exists(injector_path):\n",
    "    injector = LabelflipInjector.from_pickle(injector_path)\n",
    "else:\n",
    "    injector = LabelflipInjector(parent(model_folder), **poison_kwargs)\n",
    "x_train, y_train = injector.inject(x_train, y_train)\n",
    "data = ((x_train, y_train), current_data[1], current_data[2])\n",
    "\n",
    "# prepare unlearning data\n",
    "(x_train,  y_train), _, _ = data\n",
    "x_train, y_train, idx_reduced, delta_idx = reduce_dataset(\n",
    "    x_train, y_train, reduction=reduction, delta_idx=injector.injected_idx)\n",
    "if verbose:\n",
    "    print(f\">> reduction={reduction}, new train size: {x_train.shape[0]}\")\n",
    "y_train_orig = y_train_orig[idx_reduced]\n",
    "data = ((x_train, y_train), data[1], data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff1b82",
   "metadata": {},
   "source": [
    "Set recording file names and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b034aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_filename = dataset+\"_\"+modelname+'_poisoned_model.hdf5'\n",
    "repaired_filename = dataset+\"_\"+modelname+'_repaired_model.hdf5'\n",
    "\n",
    "update_target = update_targets[0]\n",
    "unlearning_result = UnlearningResult(model_folder, dataset, modelname+'_'+update_target)\n",
    "poisoned_weights = os.path.join(parent(model_folder), poisoned_filename)\n",
    "log_dir = model_folder\n",
    "\n",
    "# check if unlearning has already been performed\n",
    "if unlearning_result.exists:\n",
    "    print(f\"Unlearning results already exist for {modelname} {dataset}\")\n",
    "    exit()\n",
    "\n",
    "# start unlearning hyperparameter search for the poisoned model\n",
    "train_result = dataset+\"_\"+modelname+'_train_results.json'\n",
    "with open(model_folder.parents[2]/'clean'/train_result, 'r') as f:\n",
    "    clean_acc = json.load(f)['accuracy']\n",
    "repaired_filepath = os.path.join(model_folder, repaired_filename)\n",
    "cm_dir = os.path.join(model_folder, 'cm')\n",
    "os.makedirs(cm_dir, exist_ok=True)\n",
    "unlearn_kwargs['order'] = order\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72395a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), (x_valid, y_valid) = data\n",
    "params = np.sum(np.product([ xi for xi in x.shape]) for x in model().trainable_variables).item()\n",
    "\n",
    "new_theta, diverged, logs, duration_s = unlearn_update(\n",
    "        x_train, y_train, y_train_orig, delta_idx, model(), x_valid, y_valid, unlearn_kwargs, verbose=verbose, cm_dir=cm_dir, log_dir=log_dir, update_target=update_target)\n",
    "\n",
    "z_x, z_y, z_y_delta, x_val, y_val = x_train, y_train, y_train_orig, x_valid, y_valid\n",
    "\n",
    "model_weights = poisoned_weights\n",
    "new_theta = model_weights\n",
    "new_model = model_init()\n",
    "new_model().set_weights(new_theta)\n",
    "logs = LoggedGradientTape.logs['unlearn']\n",
    "\n",
    "if repaired_filepath is not None:\n",
    "        new_model.save_weights(repaired_filepath)\n",
    "acc_before, acc_after, diverged = evaluate_model_diff(\n",
    "        model, new_model, x_valid, y_valid, diverged, verbose, clean_acc)\n",
    "\n",
    "acc_perc_restored = (acc_after - acc_before) / (clean_acc - acc_before)\n",
    "unlearning_duration_s = duration_s\n",
    "print(f'Acc_after : {acc_after} \\n Acc_before : {acc_before}, \\n diverge => {diverged}')\n",
    "unlearning_result.update({\n",
    "        'acc_clean': clean_acc,\n",
    "        'acc_before_fix': acc_before,\n",
    "        'acc_after_fix': acc_after,\n",
    "        'acc_perc_restored': acc_perc_restored,\n",
    "        'diverged': diverged,\n",
    "        'n_gradients': sum(logs),\n",
    "        'unlearning_duration_s': unlearning_duration_s,\n",
    "        'num_params': params\n",
    "    })\n",
    "unlearning_result.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = poisoned_folder/'first-order'\n",
    "modelname = 'VGG16'\n",
    "dataset = 'Cifar10'\n",
    "data = Cifar10.load()\n",
    "model = model_init()\n",
    "poisoned_filename = dataset+\"_\"+modelname+'_poisoned_model.hdf5'\n",
    "repaired_filename = dataset+\"_\"+modelname+'_repaired_model.hdf5'\n",
    "\n",
    "update_targets = ['classifier', 'feature_extractor']\n",
    "orders = [1, 2]\n",
    "for order in orders:\n",
    "    for update_target in update_targets:\n",
    "        model, data = unlearn_model(update_target, model_folder, dataset, modelname, parent, poisoned_filename, repaired_filename, order, data)    \n",
    "        print(f\"Evaluation VGG CIFAR  update_target : {update_target} # order : {order}\")\n",
    "        evaluate(model=model(), data=current_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503385aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
