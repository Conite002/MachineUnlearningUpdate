{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backdoor Unlearning\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Experimental setup (generating configs)\n",
    "2. Clean model training\n",
    "3. Poisoned model training\n",
    "4. First-order unlearning\n",
    "5. Second-order unlearning\n",
    "6. Visualizing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "- All configurations to test are defined in the `[train|poison|unlearn].json` files (see below).\n",
    "- If parameters are passed as list, all their combinations are tested in a grid-search manner.\n",
    "- Only a single combination is provided for this demo. The original combinations are in `Applications/Poisoning/configs`\n",
    "- The function generates directories and configuration files for each combination. They are later used by an evaluation script to run the experiment. This allows for parallelization and distributed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if you are using CUDA devices\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import BASE_DIR\n",
    "from Applications.Poisoning.gen_configs import main as gen_configs\n",
    "\n",
    "model_folder = BASE_DIR/'models'/'poisoning'\n",
    "train_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'train.json'\n",
    "poison_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'poison.json'\n",
    "unlearn_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'unlearn.json'\n",
    "\n",
    "gen_configs(model_folder, train_conf, poison_conf, unlearn_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 08:38:49.218807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-12.2/lib64\n",
      "2024-07-12 08:38:49.218839: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from Applications.Poisoning.poison.poison_models import train_poisoned\n",
    "from Applications.Poisoning.configs.demo.config import Config\n",
    "\n",
    "poisoned_folder = model_folder/'budget-10000'/'seed-42'\n",
    "clean_folder = model_folder/'clean'\n",
    "first_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'first-order'\n",
    "second_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'second-order'\n",
    "\n",
    "\n",
    "poison_kwargs = Config.from_json(poisoned_folder/'poison_config.json')\n",
    "train_kwargs = Config.from_json(poisoned_folder/'train_config.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Model Training\n",
    "\n",
    "- Train a clean model for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Poisoned Model\n",
    "\n",
    "- Select one of the generated configurations and train a poisoned model.\n",
    "- The poisoning uses an `injector` object which can be persisted for reproducibility. It will inject the backdoors/label noise into the same samples according to a seed. In our experiments, we worked with label noise poisoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Applications.Poisoning.poison.poison_models import train_poisoned\n",
    "from Applications.Poisoning.configs.demo.config import Config\n",
    "\n",
    "poisoned_folder = model_folder/'budget-10000'/'seed-42'\n",
    "clean_folder = model_folder/'clean'\n",
    "first_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'first-order'\n",
    "second_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'second-order'\n",
    "\n",
    "\n",
    "poison_kwargs = Config.from_json(poisoned_folder/'poison_config.json')\n",
    "train_kwargs = Config.from_json(poisoned_folder/'train_config.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_weights = poisoned_folder/'best_model.hdf5'       # model that has been trained on poisoned data\n",
    "fo_repaired_weights = poisoned_folder/'fo_repaired.hdf5'   # model weights after unlearning (first-order)\n",
    "so_repaired_weights = poisoned_folder/'so_repaired.hdf5'   # model weights after unlearning (second-order)\n",
    "injector_path = poisoned_folder/'injector.pkl'             # cached injector for reproducibility\n",
    "clean_results = model_folder/'clean'/'train_results.json'  # path to reference results on clean dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlearning\n",
    "\n",
    "- Perform the first-order and second-order unlearning. The unlearning is wrapped in a function that\n",
    "    - loads the clean data, saves the original labels\n",
    "    - injects the poison (label noise)\n",
    "    - creates difference set Z using `injector.injected_idx`\n",
    "    - main unlearning happens in `Applications.Poisoning.unlearn.common.py:unlearn_update` and the thereby called `iter_approx_retraining` method\n",
    "- The variable naming follows the following ideas:\n",
    "    - `z_x`, `z_y`: features (x) and labels (y) in set `Z`\n",
    "    - `z_x_delta`, `z_y_delta`: changed features and labels (`z_x == z_x_delta` here and `z_y_delta` contains the original (fixed) labels)\n",
    "- A word about why iterative:\n",
    "    - The approximate retraining is configured to unlearn the desired changes in one step.\n",
    "    - To avoid putting a lot of redundant erroneous samples in the changing set `Z`, the iterative version\n",
    "        - takes a sub-sample (`prio_idx`) of `hvp_batch_size` in the delta set `Z`\n",
    "        - makes one unlearning step\n",
    "        - recalculates the delta set and focuses only on remaining errors\n",
    "    - The idea here is that similar to learning, it is better to work iteratively in batches since the approximation quality of the inverse hessian matrix decreases with the number of samples included (and the step size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Applications.Poisoning.unlearn.first_order import run_experiment as fo_experiment\n",
    "from Applications.Poisoning.unlearn.second_order import run_experiment as so_experiment\n",
    "\n",
    "fo_unlearn_kwargs = Config.from_json(poisoned_folder/'first-order'/'unlearn_config.json')\n",
    "so_unlearn_kwargs = Config.from_json(poisoned_folder/'second-order'/'unlearn_config.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Applications.Poisoning.train import main as train\n",
    "from Applications.Poisoning.evaluate import evaluate\n",
    "\n",
    "# train one clean and one poisoned model\n",
    "# datasets = ['Cifar10', 'Cifar100', 'SVHN', 'FashionMnist']\n",
    "datasets = ['Cifar100', 'Cifar10', 'SVHN']\n",
    "# modelnames = ['extractfeatures_VGG16', 'classifier_VGG16']\n",
    "modelnames = ['VGG16']\n",
    "# modelnames = ['VGG16', 'RESNET50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      " UNLEARNING \n",
      "############################################################\n",
      "\n",
      "\n",
      "\n",
      "* Evaluating VGG16 on Cifar100 poisoned model *\n",
      "* First-order unlearning VGG16 on Cifar100 poisoned model *\n",
      "Unlearning results already exist for VGG16 Cifar100\n",
      "* Evaluating VGG16 on Cifar100 after first-order unlearning *\n",
      "* Second-order unlearning VGG16 on Cifar100 poisoned model *\n",
      "Unlearning results already exist for /home/conite/Documents/WORKSPACE/PROJECTS/Memoire M2/code/MachineUnlearningUpdate/models/poisoning/budget-10000/seed-42/second-order\n",
      "* Evaluating VGG16 on Cifar100 after second-order unlearning *\n",
      "* Evaluating VGG16 on Cifar100 poisoned model *\n",
      "* First-order unlearning VGG16 on Cifar100 poisoned model *\n",
      "Unlearning results already exist for VGG16 Cifar100\n",
      "* Evaluating VGG16 on Cifar100 after first-order unlearning *\n",
      "* Second-order unlearning VGG16 on Cifar100 poisoned model *\n",
      "Unlearning results already exist for /home/conite/Documents/WORKSPACE/PROJECTS/Memoire M2/code/MachineUnlearningUpdate/models/poisoning/budget-10000/seed-42/second-order\n",
      "* Evaluating VGG16 on Cifar100 after second-order unlearning *\n",
      "############################################################\n",
      " UNLEARNING \n",
      "############################################################\n",
      "\n",
      "\n",
      "\n",
      "* Evaluating VGG16 on Cifar10 poisoned model *\n",
      "* First-order unlearning VGG16 on Cifar10 poisoned model *\n",
      "Loading weights from None\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "results = {\n",
    "    'clean': {},\n",
    "    'poisoned': {},\n",
    "    'first_order_unlearning': {},\n",
    "    'second_order_unlearning': {}\n",
    "}\n",
    "\n",
    "update_targets = ['classifier', 'feature_extractor']\n",
    "\n",
    "for dataset in datasets:\n",
    "    results['clean'][dataset] = {}\n",
    "    results['poisoned'][dataset] = {}\n",
    "    results['first_order_unlearning'][dataset] = {}\n",
    "    results['second_order_unlearning'][dataset] = {}\n",
    "   \n",
    "    print('#' * 60)\n",
    "    print(f\" UNLEARNING \")\n",
    "    print('#' * 60)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    for modelname in modelnames:\n",
    "        for update_target in update_targets:\n",
    "            print(f\"* Evaluating {modelname} on {dataset} poisoned model *\")\n",
    "            # poisoned_accuracy = evaluate(model_folder=poisoned_folder, dataset=dataset, modelname=modelname, type='poisoned')\n",
    "            # results['poisoned'][dataset][modelname] = poisoned_accuracy\n",
    "            \n",
    "            print(f\"* First-order unlearning {modelname} on {dataset} poisoned model *\")\n",
    "            fo_experiment(poisoned_folder/'first-order', train_kwargs, poison_kwargs, fo_unlearn_kwargs, dataset=dataset, modelname=modelname, update_target=update_target)\n",
    "            print(f\"* Evaluating {modelname} on {dataset} after first-order unlearning *\")\n",
    "            # fo_repaired_accuracy = evaluate(model_folder=first_unlearn_folder, dataset=dataset, modelname=modelname, type='repaired')\n",
    "            # results['first_order_unlearning'][dataset][modelname] = fo_repaired_accuracy\n",
    "        \n",
    "\n",
    "            print(f\"* Second-order unlearning {modelname} on {dataset} poisoned model *\")\n",
    "            so_experiment(poisoned_folder/'second-order', train_kwargs, poison_kwargs, so_unlearn_kwargs, dataset=dataset, modelname=modelname, update_target=update_target)\n",
    "            print(f\"* Evaluating {modelname} on {dataset} after second-order unlearning *\")\n",
    "            # so_repaired_accuracy = evaluate(model_folder=second_unlearn_folder, dataset=dataset, modelname=modelname, type='repaired')\n",
    "            # results['second_order_unlearning'][dataset][modelname] = so_repaired_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORGET SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def calculate_confidence(model, x_data):\n",
    "    y_pred = model.predict(x_data)\n",
    "    probs = tf.nn.softmax(y_pred, axis=1).numpy()\n",
    "    max_probs = np.max(probs, axis=1)\n",
    "    return max_probs\n",
    "\n",
    "\n",
    "def calculate_confusion_matrix(model, x_data, y_true):\n",
    "    y_pred = model.predict(x_data)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_true, axis=1) if len(y_true.shape) > 1 else y_true\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                if i == j:\n",
    "                    if i == 1:\n",
    "                        tp = cm[i, j]\n",
    "                    else:\n",
    "                        tn += cm[i, j]\n",
    "                else:\n",
    "                    if i == 1:\n",
    "                        fn += cm[i, j]\n",
    "                    else:\n",
    "                        fp += cm[i, j]\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def calculate_forget_score(tn_before, fp_before, fn_before, tp_before, tn_after, fp_after, fn_after, tp_after):\n",
    "    delta = 0.01\n",
    "    tpr_before = tp_before / (tp_before + fn_before + delta)\n",
    "    fpr_before = fp_before / (fp_before + tn_before + delta)\n",
    "    tpr_after = tp_after / (tp_after + fn_after + delta)\n",
    "    fpr_after = fp_after / (fp_after + tn_after + delta)\n",
    "\n",
    "    epsilon = np.nanmax([\n",
    "        np.log(1 - delta - fpr_after) - np.log(tpr_after),\n",
    "        np.log(1 - delta - fn_after) - np.log(tpr_after),\n",
    "        np.log(1 - delta - fpr_before) - np.log(tpr_before),\n",
    "        np.log(1 - delta - fn_before) - np.log(tpr_before)\n",
    "    ])\n",
    "\n",
    "    return epsilon\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    if len(y_true.shape) > 1:\n",
    "        y_true = np.argmax(y_true, axis=1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_model_accuracy(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    return accuracy\n",
    "\n",
    "def load_and_evaluate_models(datasets, models, clean_folder, unlearn_folder):\n",
    "    results = {}\n",
    "    \n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        results[dataset_name] = {}\n",
    "        \n",
    "        # Load the dataset\n",
    "        (x_train, y_train), (x_test, y_test), (x_valid, y_valid) = dataset.load()\n",
    "        \n",
    "        for model_name in models[dataset_name]:\n",
    "            model_fn = models[dataset_name][model_name]\n",
    "            results[dataset_name][model_name] = {}\n",
    "            print(f\"Evaluating {model_name} on {dataset_name}\")\n",
    "            \n",
    "            try:\n",
    "                # Load the clean model\n",
    "                model_clean = model_fn()\n",
    "                model_clean.load_weights(clean_folder / f'{model_name}_best_model.hdf5')\n",
    "\n",
    "                # Load the unlearned model\n",
    "                model_unlearned = model_fn()\n",
    "                model_unlearned.load_weights(unlearn_folder / f'{model_name}_repaired_model.hdf5')\n",
    "            except:\n",
    "                print(f\"Error loading models for {model_name} on {dataset_name}\")\n",
    "                continue\n",
    "            # Evaluate the accuracy of the models\n",
    "            accuracy_clean = evaluate_model_accuracy(model_clean, x_test, y_test)\n",
    "            accuracy_unlearned = evaluate_model_accuracy(model_unlearned, x_test, y_test)\n",
    "            print(f\"Accuracy of the clean model: {accuracy_clean:.4f}\")\n",
    "            print(f\"Accuracy of the unlearned model: {accuracy_unlearned:.4f}\")\n",
    "\n",
    "            # Compute confusion matrix for clean model\n",
    "            y_pred_clean = model_clean.predict(x_test).argmax(axis=1)\n",
    "            #plot_confusion_matrix(y_test, y_pred_clean, f'{model_name} Clean Model Confusion Matrix')\n",
    "\n",
    "            # Compute confusion matrix for unlearned model\n",
    "            y_pred_unlearned = model_unlearned.predict(x_test).argmax(axis=1)\n",
    "            #plot_confusion_matrix(y_test, y_pred_unlearned, f'{model_name} Unlearned Model Confusion Matrix')\n",
    "\n",
    "\n",
    "            # Compute confidence and confusion matrix for clean model\n",
    "            clean_confidences = calculate_confidence(model_clean, x_test)\n",
    "            tn_clean, fp_clean, fn_clean, tp_clean = calculate_confusion_matrix(model_clean, x_test, y_test)\n",
    "\n",
    "            # Compute confidence and confusion matrix for unlearned model\n",
    "            unlearning_confidences = calculate_confidence(model_unlearned, x_test)\n",
    "            tn_unlearned, fp_unlearned, fn_unlearned, tp_unlearned = calculate_confusion_matrix(model_unlearned, x_test, y_test)\n",
    "\n",
    "            # Calculate forget score\n",
    "            forget_score = calculate_forget_score(tn_clean, fp_clean, fn_clean, tp_clean, tn_unlearned, fp_unlearned, fn_unlearned, tp_unlearned)\n",
    "            print(f\"Forget Score for {model_name} on {dataset_name}: {forget_score:.4f}\")\n",
    "\n",
    "            results[dataset_name][model_name] = {\n",
    "                'clean_accuracy': accuracy_clean,\n",
    "                'unlearned_accuracy': accuracy_unlearned,\n",
    "                'forget_score': forget_score\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "# import TensorDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from conf import BASE_DIR\n",
    "from Applications.Poisoning.gen_configs import main as gen_configs\n",
    "from Applications.Poisoning.model import extractfeatures_VGG16, classifier_VGG16, extractfeatures_RESNET50, classifier_RESNET50, get_VGG16_CIFAR100, get_VGG16_CIFAR10, get_VGG16_SVHN, get_RESNET50_CIFAR100, get_RESNET50_CIFAR10, get_RESNET50_SVHN, extractfeatures_RESNET50_CIFAR100, extractfeatures_VGG16_CIFAR100, classifier_RESNET50_CIFAR100, classifier_VGG16_CIFAR100\n",
    "from Applications.Poisoning.dataset import Cifar10, SVHN, FashionMnist, Cifar100\n",
    "\n",
    "\n",
    "model_folder = BASE_DIR/'models'/'poisoning'\n",
    "\n",
    "datasets = {\n",
    "    'Cifar10': Cifar10,\n",
    "    'SVHN': SVHN,\n",
    "    'Cifar100': Cifar100\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'Cifar10': {\n",
    "        'Cifar10_VGG16': get_VGG16_CIFAR10,\n",
    "        'Cifar10_RESNET50': get_RESNET50_CIFAR10,\n",
    "    },\n",
    "    'SVHN': {\n",
    "        'SVHN_VGG16': get_VGG16_SVHN,\n",
    "        'SVHN_RESNET50': get_RESNET50_SVHN,\n",
    "    },\n",
    "    'Cifar100': {\n",
    "        'Cifar100_VGG16': get_VGG16_CIFAR100,\n",
    "        'Cifar100_RESNET50': get_RESNET50_CIFAR100,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "clean_folder = model_folder/'clean'\n",
    "poisoned_folder = model_folder/'budget-10000'/'seed-42'\n",
    "first_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'first-order'\n",
    "second_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'second-order'\n",
    "\n",
    "results = load_and_evaluate_models(datasets, models, clean_folder, first_unlearn_folder)\n",
    "# Print final results\n",
    "for dataset_name, dataset_results in results.items():\n",
    "    for model_name, model_results in dataset_results.items():\n",
    "        print(f\"{dataset_name} - {model_name}:\")\n",
    "        print(f\"  Clean Accuracy: {model_results['clean_accuracy']:.4f}\")\n",
    "        print(f\"  Unlearned Accuracy: {model_results['unlearned_accuracy']:.4f}\")\n",
    "        print(f\"  Forget Score: {model_results['forget_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "\n",
    "# results = {\n",
    "#     'clean': {},\n",
    "#     'poisoned': {},\n",
    "#     'first_order_unlearning': {},\n",
    "#     'second_order_unlearning': {}\n",
    "# }\n",
    "\n",
    "# update_targets = ['feature_extractor', 'classifier']\n",
    "# for dataset in datasets:\n",
    "#     for modelname in modelnames:\n",
    "#         for update_target in update_targets:\n",
    "#             print(f\"* First-order unlearning {modelname} on {dataset} poisoned model *\")\n",
    "#             fo_experiment(poisoned_folder/'first-order', train_kwargs, poison_kwargs, fo_unlearn_kwargs, dataset=dataset, modelname=modelname, update_target=update_target)\n",
    "#             print(f\" * Second-order unlearning {modelname} on {dataset} poisoned model *\")  \n",
    "#             so_experiment(poisoned_folder/'second-order', train_kwargs, poison_kwargs, so_unlearn_kwargs, dataset=dataset, modelname=modelname, update_target=update_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
