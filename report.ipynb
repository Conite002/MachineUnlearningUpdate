{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La perplexité est une mesure couramment utilisée en traitement du langage naturel (NLP) pour évaluer la qualité d'un modèle probabiliste à prédire une séquence de mots. Dans le contexte du désapprentissage, cette mesure peut être adaptée pour évaluer la performance du modèle après que certaines données ont été supprimées. Voici comment on pourrait l'adapter :\n",
    "\n",
    "Formule de la Perplexité\n",
    "La perplexité (\n",
    "𝑃\n",
    "𝑃\n",
    "𝐿\n",
    "PPL) est calculée à partir de la probabilité des prédictions du modèle :\n",
    "\n",
    "𝑃\n",
    "𝑃\n",
    "𝐿\n",
    "=\n",
    "exp\n",
    "⁡\n",
    "(\n",
    "−\n",
    "1\n",
    "𝑁\n",
    "∑\n",
    "𝑖\n",
    "=\n",
    "1\n",
    "𝑁\n",
    "log\n",
    "⁡\n",
    "𝑃\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    ")\n",
    ")\n",
    "PPL=exp(− \n",
    "N\n",
    "1\n",
    "​\n",
    " ∑ \n",
    "i=1\n",
    "N\n",
    "​\n",
    " logP(x \n",
    "i\n",
    "​\n",
    " ))\n",
    "\n",
    "où :\n",
    "\n",
    "𝑁\n",
    "N est le nombre total de mots (ou échantillons) dans le jeu de test.\n",
    "𝑃\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    ")\n",
    "P(x \n",
    "i\n",
    "​\n",
    " ) est la probabilité attribuée par le modèle au \n",
    "𝑖\n",
    "i-ème mot (ou échantillon).\n",
    "Adaptation au Désapprentissage\n",
    "Avant le Désapprentissage :\n",
    "\n",
    "Entraîner le modèle avec les données complètes.\n",
    "Calculer la perplexité sur un jeu de test complet.\n",
    "Après le Désapprentissage :\n",
    "\n",
    "Appliquer les techniques de désapprentissage pour \"oublier\" certaines données.\n",
    "Réentraîner ou ajuster le modèle.\n",
    "Calculer la nouvelle perplexité sur le même jeu de test.\n",
    "Comparaison des Perplexités\n",
    "Comparer les valeurs de perplexité avant et après le désapprentissage pour évaluer l'impact du désapprentissage sur la capacité du modèle à prédire correctement les données restantes.\n",
    "\n",
    "Exemple de Code\n",
    "python\n",
    "Copy code\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def calculate_perplexity(probs):\n",
    "    N = len(probs)\n",
    "    log_prob_sum = np.sum(np.log(probs))\n",
    "    perplexity = np.exp(-log_prob_sum / N)\n",
    "    return perplexity\n",
    "\n",
    "# Prédictions et probabilités avant désapprentissage\n",
    "probs_before = model.predict_proba(test_data[0])\n",
    "perplexity_before = calculate_perplexity(np.max(probs_before, axis=1))\n",
    "\n",
    "# Prédictions et probabilités après désapprentissage\n",
    "probs_after = model_unlearned.predict_proba(test_data[0])\n",
    "perplexity_after = calculate_perplexity(np.max(probs_after, axis=1))\n",
    "Garantie pour le Désapprentissage\n",
    "Pour garantir que les données désapprises ne sont plus influentes, on peut utiliser des techniques comme des certificats formels de désapprentissage, des tests empiriques ou des audits externes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
