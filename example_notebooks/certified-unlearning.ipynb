{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9376c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d145037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf448293",
   "metadata": {},
   "source": [
    "**1- Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Enron'\n",
    "#dataset_name = 'Drebin'  # we use the spam dataset as an example\n",
    "normalize = True  # we normalize the datapoints to have euclidean norm of 1\n",
    "# load the training and test data\n",
    "loader = DataLoader(dataset_name, normalize)\n",
    "train_data, test_data, voc = (loader.x_train, loader.y_train), (loader.x_test, loader.y_test), loader.voc\n",
    "category_to_idx_dict = loader.category_to_idx_dict\n",
    "# create folders for results\n",
    "res_save_folder = 'Results_{}'.format(dataset_name)\n",
    "model_save_folder = 'Models_{}'.format(dataset_name)\n",
    "if not os.path.isdir(res_save_folder):\n",
    "    os.makedirs(res_save_folder)\n",
    "# relevant features contain the privacy sensitive features of the dataset, (names in the case of Enron)\n",
    "relevant_features = loader.relevant_features\n",
    "relevant_indices = [voc[f] for f in relevant_features]\n",
    "# lets see some names that were found in the dataset\n",
    "print(','.join(relevant_features[:10]))\n",
    "# these features will be deleted\n",
    "indices_to_delete = relevant_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5fabf",
   "metadata": {},
   "source": [
    "**2- Model Training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24275afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Random classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modele_A = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modele_A.fit(train_data[0], train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d53f52c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9847271648873073\n",
      "F1:  0.9853672396647251\n",
      "Precision:  0.9771766694843618\n",
      "Confusion matrix: \n",
      "[[3173   81]\n",
      " [  22 3468]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "y_pred = modele_A.predict(test_data[0])\n",
    "acc = accuracy_score(test_data[1], y_pred)\n",
    "f1 = f1_score(test_data[1], y_pred)\n",
    "precision = precision_score(test_data[1], y_pred)\n",
    "conf_matrix = confusion_matrix(test_data[1], y_pred)\n",
    "print('Accuracy: ', acc)\n",
    "print('F1: ', f1)\n",
    "print('Precision: ', precision)\n",
    "print('Confusion matrix: ')\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def copy_and_replace(x, indice, remove=False, n_replacements=0):\n",
    "    x_cpy = x.copy()\n",
    "\n",
    "    if sp.issparse(x):\n",
    "        x_cpy = x_cpy.tolil()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ade2da0",
   "metadata": {},
   "source": [
    "**3- Certified Unlearning Process:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d309a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[269, 318, 352, 361, 402, 424, 485, 496, 565, 616]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "sigma = 0.1 \n",
    "epsilon = 0.1\n",
    "indices_to_delete[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8e0d6",
   "metadata": {},
   "source": [
    "**4- Evaluation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5517e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c762bd1e",
   "metadata": {},
   "source": [
    "**5- Documentation and Reporting:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592d086",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b991024e",
   "metadata": {},
   "source": [
    "**6- Validation and Certification:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1a2c8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
