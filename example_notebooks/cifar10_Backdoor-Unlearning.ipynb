{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backdoor Unlearning\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Experimental setup (generating configs)\n",
    "2. Clean model training\n",
    "3. Poisoned model training\n",
    "4. First-order unlearning\n",
    "5. Second-order unlearning\n",
    "6. Visualizing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "- All configurations to test are defined in the `[train|poison|unlearn].json` files (see below).\n",
    "- If parameters are passed as list, all their combinations are tested in a grid-search manner.\n",
    "- Only a single combination is provided for this demo. The original combinations are in `Applications/Poisoning/configs`\n",
    "- The function generates directories and configuration files for each combination. They are later used by an evaluation script to run the experiment. This allows for parallelization and distributed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if you are using CUDA devices\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import BASE_DIR\n",
    "from Applications.Poisoning.gen_configs import main as gen_configs\n",
    "\n",
    "model_folder = BASE_DIR/'models'/'poisoning'\n",
    "train_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'train.json'\n",
    "poison_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'poison.json'\n",
    "unlearn_conf = BASE_DIR/'Applications'/'Poisoning'/'configs'/'demo'/'unlearn.json'\n",
    "\n",
    "gen_configs(model_folder, train_conf, poison_conf, unlearn_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Model Training\n",
    "\n",
    "- Train a clean model for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Applications.Poisoning.train import main as train\n",
    "from Applications.Poisoning.evaluate import evaluate\n",
    "\n",
    "# train one clean and one poisoned model\n",
    "datasets = ['Cifar10', 'Cifar100', 'SVHN', 'FashionMNIST']\n",
    "modelnames = ['VGG16', 'RESNET50', 'extractfeatures_VGG16', 'extractfeatures_RESNET50', 'classifier_VGG16', 'classifier_RESNET50']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Applications.Poisoning.poison.poison_models import train_poisoned\n",
    "from Applications.Poisoning.configs.demo.config import Config\n",
    "\n",
    "poisoned_folder = model_folder/'budget-10000'/'seed-42'\n",
    "clean_folder = model_folder/'clean'\n",
    "first_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'first-order'\n",
    "second_unlearn_folder = model_folder/'budget-10000'/'seed-42'/'second-order'\n",
    "\n",
    "\n",
    "poison_kwargs = Config.from_json(poisoned_folder/'poison_config.json')\n",
    "train_kwargs = Config.from_json(poisoned_folder/'train_config.json')\n",
    "\n",
    "# train_poisoned(model_folder=poisoned_folder, poison_kwargs=poison_kwargs, train_kwargs=train_kwargs)\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     for modelname in modelnames:\n",
    "#         print('*' * 40)\n",
    "#         print(f\"* Training {modelname} on {dataset} poisoned model *\")\n",
    "#         print('*' * 40)\n",
    "#         train_poisoned(model_folder=poisoned_folder, dataset=dataset, modelname=modelname)\n",
    "#         print('*' * 40)\n",
    "#         print(f\"* Evaluating {modelname} on {dataset} poisoned model *\")\n",
    "#         print('*' * 40)\n",
    "#         evaluate(model_folder=poisoned_folder, dataset=dataset, modelname=modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_weights = poisoned_folder/'best_model.hdf5'       # model that has been trained on poisoned data\n",
    "fo_repaired_weights = poisoned_folder/'fo_repaired.hdf5'   # model weights after unlearning (first-order)\n",
    "so_repaired_weights = poisoned_folder/'so_repaired.hdf5'   # model weights after unlearning (second-order)\n",
    "injector_path = poisoned_folder/'injector.pkl'             # cached injector for reproducibility\n",
    "clean_results = model_folder/'clean'/'train_results.json'  # path to reference results on clean dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlearning\n",
    "\n",
    "- Perform the first-order and second-order unlearning. The unlearning is wrapped in a function that\n",
    "    - loads the clean data, saves the original labels\n",
    "    - injects the poison (label noise)\n",
    "    - creates difference set Z using `injector.injected_idx`\n",
    "    - main unlearning happens in `Applications.Poisoning.unlearn.common.py:unlearn_update` and the thereby called `iter_approx_retraining` method\n",
    "- The variable naming follows the following ideas:\n",
    "    - `z_x`, `z_y`: features (x) and labels (y) in set `Z`\n",
    "    - `z_x_delta`, `z_y_delta`: changed features and labels (`z_x == z_x_delta` here and `z_y_delta` contains the original (fixed) labels)\n",
    "- A word about why iterative:\n",
    "    - The approximate retraining is configured to unlearn the desired changes in one step.\n",
    "    - To avoid putting a lot of redundant erroneous samples in the changing set `Z`, the iterative version\n",
    "        - takes a sub-sample (`prio_idx`) of `hvp_batch_size` in the delta set `Z`\n",
    "        - makes one unlearning step\n",
    "        - recalculates the delta set and focuses only on remaining errors\n",
    "    - The idea here is that similar to learning, it is better to work iteratively in batches since the approximation quality of the inverse hessian matrix decreases with the number of samples included (and the step size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Applications.Poisoning.unlearn.first_order import run_experiment as fo_experiment\n",
    "from Applications.Poisoning.unlearn.second_order import run_experiment as so_experiment\n",
    "\n",
    "fo_unlearn_kwargs = Config.from_json(poisoned_folder/'first-order'/'unlearn_config.json')\n",
    "so_unlearn_kwargs = Config.from_json(poisoned_folder/'second-order'/'unlearn_config.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    for modelname in modelnames:\n",
    "        print('*' * 40)\n",
    "        print(f\"* Evaluating {modelname} on {dataset} poisoned model *\")\n",
    "        print('*' * 40)\n",
    "        evaluate(model_folder=poisoned_folder, dataset=dataset, modelname=modelname, type='poisoned')\n",
    "        \n",
    "        print('*' * 40)\n",
    "        print(f\"* First-order unlearning {modelname} on {dataset} poisoned model *\")\n",
    "        print('*' * 40)\n",
    "        fo_experiment(poisoned_folder, fo_unlearn_kwargs, dataset, modelname, clean_results)\n",
    "        \n",
    "        print('*' * 40)\n",
    "        print(f\"* Evaluating {modelname} on {dataset} after first-order unlearning *\")\n",
    "        print('*' * 40)\n",
    "        evaluate(model_folder=first_unlearn_folder, dataset=dataset, modelname=modelname, type='repaired')\n",
    "\n",
    "        print('*' * 40)\n",
    "        print(f\"* Second-order unlearning {modelname} on {dataset} poisoned model *\")\n",
    "        print('*' * 40)\n",
    "        so_experiment(poisoned_folder, so_unlearn_kwargs, dataset, modelname, clean_results)\n",
    "\n",
    "        print('*' * 40)\n",
    "        print(f\"* Evaluating {modelname} on {dataset} after second-order unlearning *\")\n",
    "        print('*' * 40)\n",
    "        evaluate(model_folder=second_unlearn_folder, dataset=dataset, modelname=modelname, type='repaired')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model_weights :None\n",
      "Loading weights from None\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/conite/Documents/WORKSPACE/PROJECTS/Memoire M2/code/MachineUnlearningUpdate/models/poisoning/budget-10000/seed-42/Cifar10_VGG19_poisoned_model.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42688/2017176110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mso_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoisoned_folder\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'second-order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoison_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfo_unlearn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Cifar10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VGG19'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'so_clean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/WORKSPACE/PROJECTS/Memoire M2/code/MachineUnlearningUpdate/Applications/Poisoning/unlearn/second_order.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model_folder, train_kwargs, poison_kwargs, unlearn_kwargs, reduction, verbose, classes, dataset, modelname, update_target, model_weights, prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model model_weights :{model_weights}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     second_order_unlearning(model_folder, poisoned_filename, repaired_filename, model_init, data, y_train_orig,\n\u001b[0;32m--> 123\u001b[0;31m                             injector.injected_idx, unlearn_kwargs, verbose=verbose, dataset=dataset, modelname=modelname, update_target=update_target, model_weights=model_weights,prefix=prefix)\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/WORKSPACE/PROJECTS/Memoire M2/code/MachineUnlearningUpdate/Applications/Poisoning/unlearn/second_order.py\u001b[0m in \u001b[0;36msecond_order_unlearning\u001b[0;34m(model_folder, poisoned_filename, repaired_filename, model_init, data, y_train_orig, delta_idx, unlearn_kwargs, order, verbose, dataset, modelname, update_target, prefix, model_weights)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0munlearn_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     acc_before, acc_after, diverged, logs, unlearning_duration_s, params = evaluate_unlearning(model_init, poisoned_weights, data, delta_idx, y_train_orig, unlearn_kwargs, clean_acc=clean_acc,\n\u001b[0;32m--> 145\u001b[0;31m                                                                                        repaired_filepath=repaired_filepath, verbose=verbose, cm_dir=cm_dir, log_dir=log_dir, update_target=update_target,  model_weight=model_weights)\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0macc_perc_restored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc_after\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0macc_before\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclean_acc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0macc_before\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/WORKSPACE/PROJECTS/Memoire M2/code/MachineUnlearningUpdate/Applications/Poisoning/unlearn/common.py\u001b[0m in \u001b[0;36mevaluate_unlearning\u001b[0;34m(model_init, model_weights, data, delta_idx, y_train_orig, unlearn_kwargs, repaired_filepath, clean_acc, verbose, cm_dir, log_dir, update_target, model_weight)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m# print accuracy model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/ML_ENV/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/ML_ENV/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/ML_ENV/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/conite/Documents/WORKSPACE/PROJECTS/Memoire M2/code/MachineUnlearningUpdate/models/poisoning/budget-10000/seed-42/Cifar10_VGG19_poisoned_model.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "so_experiment(poisoned_folder/'second-order', train_kwargs, poison_kwargs, fo_unlearn_kwargs, dataset='Cifar10', modelname='VGG19', update_target='classifier', prefix='so_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
